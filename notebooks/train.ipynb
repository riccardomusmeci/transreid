{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fcf8a70",
   "metadata": {},
   "source": [
    "# **Train Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d08c57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import sagemaker\n",
    "from sagemaker.pytorch.estimator import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5113767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'enel-noprod-glin-ap35001-odin1'\n",
    "ROLE = 'arn:aws:iam::856657991664:role/GG-SH-AWS-Enel-GLINSviCol-glin-ap35001_sb_reduce'\n",
    "TAGS = [\n",
    "    {'Key': 'sc', 'Value': 'glin'},\n",
    "    {'Key': 'Gias_ID', 'Value': 'AP35001'},\n",
    "    {'Key': 'env', 'Value': 'sb'},\n",
    "]\n",
    "PREFIX = 'glin-ap35001-sb-smtj-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "00883e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_DATASET = \"s3://enel-noprod-glin-ap35001-sandbox/ODIN/S0010639/transreid/dataset/Market1501/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f95b9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "MODEL_NAME = f\"lighting-reid-market-{DATE}\"\n",
    "TRAIN_BASE_JOB_NAME = f'{PREFIX}{MODEL_NAME}'\n",
    "TRAIN_JOB_NAME = f'{TRAIN_BASE_JOB_NAME}'\n",
    "OUTPUT_DIR = f\"s3://enel-noprod-glin-ap35001-sandbox/ODIN/S0010639/transreid/output/{TRAIN_JOB_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "320eb66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name lighting-reid-market-2022-07-15-19-17-58\n",
      "Train Job Name glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58\n",
      "Output S3 dir s3://enel-noprod-glin-ap35001-sandbox/ODIN/S0010639/transreid/output/glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model name {MODEL_NAME}\")\n",
    "print(f\"Train Job Name {TRAIN_JOB_NAME}\")\n",
    "print(f\"Output S3 dir {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dfe6075b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 's3://enel-noprod-glin-ap35001-sandbox/ODIN/S0010639/transreid/dataset/Market1501/'}\n"
     ]
    }
   ],
   "source": [
    "TRAIN_INPUTS = {\n",
    "    \"dataset\": S3_DATASET\n",
    "}\n",
    "print(TRAIN_INPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5df3489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_estimator = PyTorch(\n",
    "    source_dir =\"../\",\n",
    "    entry_point=\"train.py\",\n",
    "    sagemaker_session=sagemaker.Session(default_bucket=BUCKET), \n",
    "    role=ROLE,\n",
    "    tags=TAGS,\n",
    "    py_version='py38',\n",
    "    framework_version='1.10.0',\n",
    "    instance_type=\"ml.p3.8xlarge\",\n",
    "    instance_count=1,\n",
    "    volume_size=100,\n",
    "    base_job_name=TRAIN_BASE_JOB_NAME,\n",
    "#    hyperparameters=TRAIN_HYPERPARAMS,\n",
    "    output_path=f\"{OUTPUT_DIR}/output\",\n",
    "    checkpoint_local_path='/opt/ml/checkpoints/',\n",
    "    checkpoint_s3_uri=f\"{OUTPUT_DIR}/checkpoints\",\n",
    "    debugger_hook_config=False,\n",
    "    code_location=f\"{OUTPUT_DIR}/code\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63ce33a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-15 19:18:09 Starting - Starting the training job...ProfilerReport-1657912689: InProgress\n",
      "...\n",
      "2022-07-15 19:18:56 Starting - Preparing the instances for training......\n",
      "2022-07-15 19:20:00 Downloading - Downloading input data...........................................................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-07-15 19:29:57,703 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-07-15 19:29:57,743 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-07-15 19:29:57,749 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-07-15 19:29:58,403 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (4.61.2)\u001b[0m\n",
      "\u001b[34mCollecting timm==0.5.4\u001b[0m\n",
      "\u001b[34mDownloading timm-0.5.4-py3-none-any.whl (431 kB)\u001b[0m\n",
      "\u001b[34mCollecting glob2==0.7\u001b[0m\n",
      "\u001b[34mDownloading glob2-0.7.tar.gz (10 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics==0.3.2\u001b[0m\n",
      "\u001b[34mDownloading torchmetrics-0.3.2-py3-none-any.whl (274 kB)\u001b[0m\n",
      "\u001b[34mCollecting albumentations==1.0.0\u001b[0m\n",
      "\u001b[34mDownloading albumentations-1.0.0-py3-none-any.whl (98 kB)\u001b[0m\n",
      "\u001b[34mCollecting pytorch_toolbelt==0.4.3\u001b[0m\n",
      "\u001b[34mDownloading pytorch_toolbelt-0.4.3.tar.gz (118 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning==1.3.7.post0\u001b[0m\n",
      "\u001b[34mDownloading pytorch_lightning-1.3.7.post0-py3-none-any.whl (810 kB)\u001b[0m\n",
      "\n",
      "2022-07-15 19:29:57 Training - Training image download completed. Training in progress.\u001b[34mCollecting pytorch-metric-learning\u001b[0m\n",
      "\u001b[34mDownloading pytorch_metric_learning-1.5.0-py3-none-any.whl (110 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm==0.5.4->-r requirements.txt (line 2)) (0.11.1+cu113)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.8/site-packages (from timm==0.5.4->-r requirements.txt (line 2)) (1.10.0+cu113)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from torchmetrics==0.3.2->-r requirements.txt (line 4)) (21.3)\u001b[0m\n",
      "\u001b[34mCollecting scikit-image>=0.16.1\u001b[0m\n",
      "\u001b[34mDownloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.8/site-packages (from albumentations==1.0.0->-r requirements.txt (line 5)) (1.21.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from albumentations==1.0.0->-r requirements.txt (line 5)) (1.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from albumentations==1.0.0->-r requirements.txt (line 5)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting opencv-python-headless>=4.1.1\u001b[0m\n",
      "\u001b[34mDownloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opencv-python>=4.1 in /opt/conda/lib/python3.8/site-packages (from pytorch_toolbelt==0.4.3->-r requirements.txt (line 6)) (4.5.4.60)\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate==0.3.0\u001b[0m\n",
      "\u001b[34mDownloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard!=2.5.0,>=2.2.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (2021.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from pytorch-metric-learning->-r requirements.txt (line 8)) (1.0.1)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (2.26.0)\u001b[0m\n",
      "\u001b[34mCollecting tifffile>=2019.7.26\u001b[0m\n",
      "\u001b[34mDownloading tifffile-2022.5.4-py3-none-any.whl (195 kB)\u001b[0m\n",
      "\u001b[34mCollecting networkx>=2.2\u001b[0m\n",
      "\u001b[34mDownloading networkx-2.8.4-py3-none-any.whl (2.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting PyWavelets>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading PyWavelets-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations==1.0.0->-r requirements.txt (line 5)) (2.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations==1.0.0->-r requirements.txt (line 5)) (8.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->torchmetrics==0.3.2->-r requirements.txt (line 4)) (3.0.6)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.47.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34mDownloading absl_py-1.1.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (59.2.0)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.4.1-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (2.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (0.36.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (3.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 2)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->pytorch-metric-learning->-r requirements.txt (line 8)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->pytorch-metric-learning->-r requirements.txt (line 8)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (4.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (21.2.0)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (3.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.7.post0->-r requirements.txt (line 7)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: glob2, pytorch-toolbelt\u001b[0m\n",
      "\u001b[34mBuilding wheel for glob2 (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for glob2 (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for glob2: filename=glob2-0.7-py2.py3-none-any.whl size=9320 sha256=e3a227bf55bf0005536a4bb769b7236c0b214a14650541b930916b003db56fe0\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/95/59/ed/52469ecfae47a78c25f11bcb49db42ff84629df01861876883\u001b[0m\n",
      "\u001b[34mBuilding wheel for pytorch-toolbelt (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for pytorch-toolbelt (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for pytorch-toolbelt: filename=pytorch_toolbelt-0.4.3-py3-none-any.whl size=161611 sha256=fcaaf25af3577626d644ae79cea33c5b7264d413d86c0a4930be1d2ac723f845\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/d1/40/61/c66ac6b52bc9e420b6480c65c1c443de44040c8fcd0b96a46b\u001b[0m\n",
      "\u001b[34mSuccessfully built glob2 pytorch-toolbelt\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyasn1-modules, oauthlib, multidict, frozenlist, cachetools, yarl, requests-oauthlib, google-auth, async-timeout, aiosignal, tifffile, tensorboard-plugin-wit, tensorboard-data-server, PyWavelets, networkx, markdown, grpcio, google-auth-oauthlib, aiohttp, absl-py, torchmetrics, tensorboard, scikit-image, pyDeprecate, opencv-python-headless, timm, pytorch-toolbelt, pytorch-metric-learning, pytorch-lightning, glob2, albumentations\u001b[0m\n",
      "\u001b[34mSuccessfully installed PyWavelets-1.3.0 absl-py-1.1.0 aiohttp-3.8.1 aiosignal-1.2.0 albumentations-1.0.0 async-timeout-4.0.2 cachetools-5.2.0 frozenlist-1.3.0 glob2-0.7 google-auth-2.9.1 google-auth-oauthlib-0.4.6 grpcio-1.47.0 markdown-3.4.1 multidict-6.0.2 networkx-2.8.4 oauthlib-3.2.0 opencv-python-headless-4.6.0.66 pyDeprecate-0.3.0 pyasn1-modules-0.2.8 pytorch-lightning-1.3.7.post0 pytorch-metric-learning-1.5.0 pytorch-toolbelt-0.4.3 requests-oauthlib-1.3.1 scikit-image-0.19.3 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tifffile-2022.5.4 timm-0.5.4 torchmetrics-0.3.2 yarl-1.7.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-07-15 19:30:17,030 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"dataset\": \"/opt/ml/input/data/dataset\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"dataset\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://enel-noprod-glin-ap35001-sandbox/ODIN/S0010639/transreid/output/glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58/code/glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.8xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.8xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"dataset\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://enel-noprod-glin-ap35001-sandbox/ODIN/S0010639/transreid/output/glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58/code/glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"dataset\":\"/opt/ml/input/data/dataset\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://enel-noprod-glin-ap35001-sandbox/ODIN/S0010639/transreid/output/glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58/code/glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_DATASET=/opt/ml/input/data/dataset\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 train.py\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\u001b[0m\n",
      "\u001b[34mGlobal seed set to 42\u001b[0m\n",
      "\u001b[34m['query', 'bounding_box_test', 'bounding_box_train', 'readme.txt', 'gt_bbox', 'gt_query']\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mGPU available: True, used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34mUsing native 16bit precision.\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[0m\n",
      "\n",
      "2022-07-15 19:30:45 Uploading - Uploading generated training model\n",
      "2022-07-15 19:30:45 Failed - Training job failed\n",
      "\u001b[34m| Name     | Type               | Params\u001b[0m\n",
      "\u001b[34m------------------------------------------------\u001b[0m\n",
      "\u001b[34m0 | model    | TransReID          | 26.7 M\u001b[0m\n",
      "\u001b[34m1 | loss     | SoftmaxTripletLoss | 0     \u001b[0m\n",
      "\u001b[34m2 | accuracy | Accuracy           | 0     \u001b[0m\n",
      "\u001b[34m------------------------------------------------\u001b[0m\n",
      "\u001b[34m26.7 M    Trainable params\u001b[0m\n",
      "\u001b[34m1.9 K     Non-trainable params\u001b[0m\n",
      "\u001b[34m26.7 M    Total params\u001b[0m\n",
      "\u001b[34m106.657   Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[34mValidation sanity check: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mValidation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 4, in <module>\u001b[0m\n",
      "\u001b[34mtrain()\n",
      "  File \"/opt/ml/code/src/core/train.py\", line 52, in train\n",
      "    trainer.fit(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 458, in fit\u001b[0m\n",
      "\u001b[34mself._run(model)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 756, in _run\u001b[0m\n",
      "\u001b[34mself.dispatch()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 797, in dispatch\u001b[0m\n",
      "\u001b[34mself.accelerator.start_training(self)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 96, in start_training\u001b[0m\n",
      "\u001b[34mself.training_type_plugin.start_training(trainer)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 144, in start_training\u001b[0m\n",
      "\u001b[34mself._results = trainer.run_stage()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 807, in run_stage\u001b[0m\n",
      "\u001b[34mreturn self.run_train()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 842, in run_train\u001b[0m\n",
      "\u001b[34mself.run_sanity_check(self.lightning_module)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1107, in run_sanity_check\u001b[0m\n",
      "\u001b[34mself.run_evaluation()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 962, in run_evaluation\u001b[0m\n",
      "\u001b[34moutput = self.evaluation_loop.evaluation_step(batch, batch_idx, dataloader_idx)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 174, in evaluation_step\u001b[0m\n",
      "\u001b[34moutput = self.trainer.accelerator.validation_step(args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 226, in validation_step\u001b[0m\n",
      "\u001b[34mreturn self.training_type_plugin.validation_step(*args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in validation_step\u001b[0m\n",
      "\u001b[34mreturn self.lightning_module.validation_step(*args, **kwargs)\n",
      "  File \"/opt/ml/code/src/model/model.py\", line 80, in validation_step\n",
      "    features, logits = self(x, asset)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1131, in _call_impl\u001b[0m\n",
      "\u001b[34mreturn forward_call(*input, **kwargs)\n",
      "  File \"/opt/ml/code/src/model/model.py\", line 57, in forward\u001b[0m\n",
      "\u001b[34mreturn self.model(x, asset)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1131, in _call_impl\u001b[0m\n",
      "\u001b[34mreturn forward_call(*input, **kwargs)\n",
      "  File \"/opt/ml/code/src/model/transreid.py\", line 74, in forward\u001b[0m\n",
      "\u001b[34mx = self.backbone(x, side_info)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1131, in _call_impl\u001b[0m\n",
      "\u001b[34mreturn forward_call(*input, **kwargs)\n",
      "  File \"/opt/ml/code/src/model/vit.py\", line 65, in forward\u001b[0m\n",
      "\u001b[34msie_val = self.sie_val(side_info)\n",
      "  File \"/opt/ml/code/src/model/vit.py\", line 46, in sie_val\n",
      "    sie_val[img_idx] += asset_num * self.sie_embed[asset_idx]\u001b[0m\n",
      "\u001b[34mRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\u001b[0m\n",
      "\u001b[34m2022-07-15 19:30:33,196 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2022-07-15 19:30:33,196 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\u001b[0m\n",
      "\u001b[34m\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 train.py\"\u001b[0m\n",
      "\u001b[34m2022-07-15 19:30:33,196 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\"\nCommand \"/opt/conda/bin/python3.8 train.py\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-bbffefd79b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_INPUTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_JOB_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3337\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3338\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3339\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3340\u001b[0m             )\n\u001b[1;32m   3341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job glin-ap35001-sb-smtj-lighting-reid-market-2022-07-15-19-17-58: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\"\nCommand \"/opt/conda/bin/python3.8 train.py\", exit code: 1"
     ]
    }
   ],
   "source": [
    "train_estimator.fit(\n",
    "    inputs=TRAIN_INPUTS,\n",
    "    job_name=TRAIN_JOB_NAME,\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08f870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
